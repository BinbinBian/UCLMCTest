% Selecting the sentence with the most words in common is
% is a clear disadvantage, since MCTest has questions whose answer may be in contained in multiple sentences, and, running matching the bag of words between the entire passage and the question-answer pair would score poorly, since this would score how similar is the QA pair to the story on the basis of term frequency.

To improve on answering questions that need multiple sentences, we propose to run the bag-of-words between each question-answer pair and the $n$ most relevant sentences for the question; such problem reduces to ``Learning to Rank" task. Previous attempts of retrieving the sentences with the highest relevance for question answering have been already proved successful in the literature \cite{qa_techniques,deep_selection}. %TODO better context?
The process consist in retrieving the top $n$ ranked documents, (in this case, sentences) for a query $Q$. All the sentences $S_i$ in the story $S$ are scored by a scoring function $SentenceScore(Q, S_i)$ and then ranked.

Choosing the right query for sentence retrieval is as important as the implementation of the scoring function. Initially, our query was a stemmed and stop-words cleaned version of the question. Following an evaluation on the MC160 development set, we found that in some cases the sentences retrieved were relevant to the answer, but not to the question. For example (see Figure~\ref{fig:exampleMCT}), {\em ``Who was having a birthday?"} contains the right keyword {\em ``birthday"} to understand that the first sentence in the passage contains the answer, however {\em ``How did Jessie get ready for the party?"} does not. Sentences like {\em ``She was having a party"} will very likely have an higher score than {\em ``She made a big cake, and hung up some balloons."} which exactly contains the correct answer ($B$). Hence, we decided to also consider a combination of question and answer as alternative to question-only query.

It is beyond the interest of this paper to improve on ranking relevant sentences; hence, we use our $TokenMatchingScore$ to score each sentence and combination of it with pre-processing (in detail in Section~\ref{sec:combined})