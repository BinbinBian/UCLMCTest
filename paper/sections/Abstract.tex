MCTest is a recently developed task for evaluating machine comprehension of text. We aim at approaching the task with shallow methods and a rule-based systems.
We start with a simple token matching baseline and we enhance it through additional pre-processing (i.e. co-reference resolution, hypernymy).
Using combinations of lexical features, we train a scoring function to score multiple-choice answers.
Introducing a simple matching rules system, we outperform the current systems by 4\% and 1\% in both the given datasets. Then we use the rule-based system to analyse the MCTest datasets, by evaluating the impact on performance of each rule.