In addition to the previous methods, we also developed a rule-based scoring system. This applies a series of transformations to the story text, and assigns weights to each word, based on the conditions required to answer a given question. For example, questions requiring negation will cause the weight value for each word to be inverted, since we will need to search for the answer that is least likely to be inferred by the story.

Each rule consists of a syntactic or lexical pattern, which filters question-answer pairs into categories, according to certain empirically-designed criteria. If a question falls into one or more of these categories, a corresponding story transformation procedure is invoked. Each procedure may add or remove words from the story, or alter the weight value associated with each word. There are several base transformations applied for all questions, including lemmatization and removal of stopwords.

Some examples of our rule-based question filters are:

\textit{Negation}. Negation covers questions such as ``What did James not eat for dinner?''. These questions are a distinct special-case, which cannot be solved by simply selecting the answer with the highest similarity to the story, as all of our other methods do. We detected negative questions using the syntactic dependency graph of the question string: a question is negative if and only if the sentential root is linked to any other node by a negated dependency.

\textit{Character-subject}. Character-subject questions are those which directly concern the actions of a named character, such as ``Why did Jon go to the park?''. Any question with a named entity as a nominal-subject dependent of the question's head verb was deemed to be a character-subject question.

\textit{Narrative}. Narrative questions are those which pertain to the structure of the story itself, for example ``Which character was first mentioned in the story?''. These questions necessitate that a given system understands the concept of a story, which will have characters and a defined narrative flow, rather than simply viewing it as an unstructured piece of text. We detected these instances using a series of cue-words, such as ``story'', ``passage'' or ``character''. These cues indicate that the question acknowledges the concept of a story.

An example of a story transformation procedure would be to apply co-reference to the story if a character-subject question is detected, in order to more accurately locate the required entity. After all transformations have been applied for a given question, the transformed and weighted story is passed to a scoring function. The results we present use a sliding-window scoring function, in order to be comparable to \newcite{mctest}.

In our implementation, we opted to use a small number of heuristic transformations, which gave us minor overall improvements. However, it should be noted that the improvements of the rule-based transformations were less significant when compared to the effect of the non-rule-based transformations, such as lemmatization. It was not our intent to over-engineer a large number of question rules, when it would be built upon a shallow lexical scoring function. This system was primarily designed as an analytical tool, which we use to study the performance and limitations of a lexical system. This analysis is presented in Section~\ref{sec:evaluation}. In addition to this, it also serves as a proof-of-concept for a system with more sophisticated transformation procedures. 
